{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Deploy Best Model to an Online Endpoint\n",
        "\n",
        "Use this notebook to convert the best trained model into an MLflow artifact, register it with Azure ML, and deploy it to a managed online endpoint."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. Prerequisites\n",
        "\n",
        "Make sure you have:\n",
        "\n",
        "- Run `run_pipeline.py` (or the pipeline from `main.ipynb`) so that `outputs/model_output/<model_name>_model.pkl` exists locally.\n",
        "- `azure-ai-ml>=1.14.0`, `mlflow`, and `azure-identity` installed in the current environment.\n",
        "- `config.env` populated with your workspace and data asset settings.\n",
        "\n",
        "If you are on a compute instance, these requirements should already be satisfied.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Register Required Resource Providers\n",
        "\n",
        "If Azure returns `ResourceOperationFailure: Resource provider [N/A] isn't registered with Subscription [N/A]`, register the missing providers before proceeding:\n",
        "\n",
        "- Azure Portal → **Subscriptions** → pick the target subscription\n",
        "- **Settings** → **Resource providers** → register anything marked `NotRegistered`\n",
        "- Confirm at least `Microsoft.MachineLearningServices`, `Microsoft.PolicyInsights`, `Microsoft.Cdn`, `Microsoft.ContainerRegistry`, `Microsoft.Storage`, `Microsoft.KeyVault`, and `Microsoft.ManagedIdentity` are registered\n",
        "- Wait a few minutes for propagation, then rerun the notebook\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Workflow at a Glance\n",
        "\n",
        "1. Locate the freshest MLflow bundle produced by the training pipeline.\n",
        "2. Connect to the Azure ML workspace using the credentials defined in `config.env`.\n",
        "3. Register the model so deployments can reference a versioned asset.\n",
        "4. Create (or recycle) a managed endpoint, deploy the model, and route traffic.\n",
        "5. Invoke the endpoint for a smoke test, then delete it if you only needed a temporary environment.\n",
        "\n",
        "Use the numbered sections below to walk through each stage sequentially.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Set Up Environment\n",
        "\n",
        "Initialize paths and ensure the notebook runs from the repo root so that source imports and artifacts resolve correctly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project root: /workspaces/customer-churn-prediction-azureml\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "from azure.ai.ml.entities import Model, ManagedOnlineEndpoint, ManagedOnlineDeployment\n",
        "from azure.ai.ml.constants import AssetTypes\n",
        "\n",
        "NOTEBOOK_ROOT = Path.cwd().resolve()\n",
        "PROJECT_ROOT = NOTEBOOK_ROOT if (NOTEBOOK_ROOT / \"src\").exists() else NOTEBOOK_ROOT.parent\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "from src.utils import load_azure_config\n",
        "\n",
        "print(f\"Project root: {PROJECT_ROOT}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Locate Model Artifacts\n",
        "\n",
        "Pick the latest MLflow bundle (or honor AML_MLFLOW_BUNDLE_PATH) and record the resource names used later.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Quick reference**\n",
        "\n",
        "- `AML_MLFLOW_BUNDLE_PATH`: override to point at a specific exported bundle.\n",
        "- `AML_DEPLOY_MODEL_NAME`: registered model name in Azure ML.\n",
        "- `AML_ONLINE_ENDPOINT_NAME`: reuse an existing endpoint name instead of the timestamp default.\n",
        "- `AML_ONLINE_DEPLOYMENT_NAME`: deployment slot (e.g., `blue`, `green`).\n",
        "\n",
        "Set these before executing this notebook if you need deterministic values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Using MLflow bundle: /workspaces/customer-churn-prediction-azureml/outputs/xgboost_mlflow\n",
            "Model asset name: bank-churn-best-model\n",
            "Endpoint name: churn-endpoint-1763549164\n",
            "Deployment name: blue\n"
          ]
        }
      ],
      "source": [
        "# User Inputs\n",
        "OUTPUTS_DIR = PROJECT_ROOT / \"outputs\"\n",
        "\n",
        "MLFLOW_MODEL_DIR = None\n",
        "env_mlflow_path = os.getenv(\"AML_MLFLOW_BUNDLE_PATH\")\n",
        "if env_mlflow_path:\n",
        "    MLFLOW_MODEL_DIR = Path(env_mlflow_path)\n",
        "elif OUTPUTS_DIR.exists():\n",
        "    mlflow_bundles = sorted(\n",
        "        [d for d in OUTPUTS_DIR.iterdir() if d.is_dir() and d.name.endswith(\"_mlflow\")],\n",
        "        key=lambda p: p.stat().st_mtime if p.exists() else 0,\n",
        "        reverse=True,\n",
        "    )\n",
        "    if mlflow_bundles:\n",
        "        MLFLOW_MODEL_DIR = mlflow_bundles[0]\n",
        "\n",
        "if not MLFLOW_MODEL_DIR:\n",
        "    available = \"\\n\".join(str(p) for p in OUTPUTS_DIR.glob(\"*_mlflow\")) or \"(no *_mlflow bundles found)\"\n",
        "    raise FileNotFoundError(\n",
        "        \"No MLflow bundles (*_mlflow/) were found.\\n\"\n",
        "        \"Run run_pipeline.py locally or download the best-model artifacts from the pipeline run, \"\n",
        "        \"then place them inside outputs/ or set AML_MLFLOW_BUNDLE_PATH.\\n\"\n",
        "        f\"Current outputs listing:\\n{available}\"\n",
        "    )\n",
        "\n",
        "# Names for Azure resources\n",
        "MODEL_NAME = os.getenv(\"AML_DEPLOY_MODEL_NAME\", \"bank-churn-best-model\")\n",
        "ENDPOINT_NAME = os.getenv(\"AML_ONLINE_ENDPOINT_NAME\", f\"churn-endpoint-{int(time.time())}\")\n",
        "DEPLOYMENT_NAME = os.getenv(\"AML_ONLINE_DEPLOYMENT_NAME\", \"blue\")\n",
        "\n",
        "print(f\"✓ Using MLflow bundle: {MLFLOW_MODEL_DIR}\")\n",
        "print(f\"Model asset name: {MODEL_NAME}\")\n",
        "print(f\"Endpoint name: {ENDPOINT_NAME}\")\n",
        "print(f\"Deployment name: {DEPLOYMENT_NAME}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Connect to Azure ML\n",
        "\n",
        "Load workspace settings and create an MLClient with default credentials (falling back to interactive auth if needed).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connected to workspace: churn-ml-workspace | resource group: rg-churn-ml-project-2025-11-15\n"
          ]
        }
      ],
      "source": [
        "# Connect to Azure ML workspace\n",
        "load_dotenv(PROJECT_ROOT / \"config.env\")\n",
        "\n",
        "azure_cfg = load_azure_config()\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception:\n",
        "    credential = InteractiveBrowserCredential()\n",
        "\n",
        "ml_client = MLClient(\n",
        "    credential,\n",
        "    subscription_id=azure_cfg[\"subscription_id\"],\n",
        "    resource_group_name=azure_cfg[\"resource_group\"],\n",
        "    workspace_name=azure_cfg[\"workspace_name\"],\n",
        ")\n",
        "print(\n",
        "    f\"Connected to workspace: {ml_client.workspace_name} | \"\n",
        "    f\"resource group: {ml_client.resource_group_name}\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Register the MLflow Model\n",
        "\n",
        "Upload the MLflow directory as a managed model asset so deployments can reference it.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Endpoint hygiene tips**\n",
        "\n",
        "- Azure may leave a previous endpoint in `Failed` or `Deleting`; delete it before recreating to avoid BadRequest errors.\n",
        "- CLI fallback when SDK delete hangs:\n",
        "  - `az ml online-endpoint delete --name <endpoint> --yes`\n",
        "  - `az ml online-endpoint show --name <endpoint> --query provisioning_state`\n",
        "- Generation of a new endpoint name is cheap—prefer that when the resource is stuck in an unrecoverable state.\n",
        "\n",
        "Run the cell below only after confirming the subscription resource providers are registered.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Registered model: bank-churn-best-model:3\n"
          ]
        }
      ],
      "source": [
        "# Register MLflow model asset\n",
        "model_asset = Model(\n",
        "    name=MODEL_NAME,\n",
        "    path=str(MLFLOW_MODEL_DIR),\n",
        "    type=AssetTypes.MLFLOW_MODEL,\n",
        "    description=\"Best churn model exported from training pipeline\",\n",
        ")\n",
        "registered_model = ml_client.models.create_or_update(model_asset)\n",
        "print(f\"Registered model: {registered_model.name}:{registered_model.version}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prepare the Managed Endpoint\n",
        "\n",
        "Delete any failed endpoint with the same name, then create a fresh managed online endpoint.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Deployment knobs**\n",
        "\n",
        "| Env var | Default | Purpose |\n",
        "| --- | --- | --- |\n",
        "| `AML_ONLINE_INSTANCE_TYPE` | `Standard_D2as_v4` | VM SKU for scoring. Switch to a smaller size if you hit quota limits. |\n",
        "| `AML_ONLINE_INSTANCE_COUNT` | `1` | Number of replicas. Scale out only after validating cost. |\n",
        "\n",
        "If you see `ImageBuildFailure` or quota errors, revisit the environment definition or lower the SKU before re-running.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint ready: churn-endpoint-1763549164\n"
          ]
        }
      ],
      "source": [
        "# Create or update managed online endpoint\n",
        "# Check if endpoint already exists and delete if in failed state\n",
        "try:\n",
        "    existing_endpoint = ml_client.online_endpoints.get(ENDPOINT_NAME)\n",
        "    if existing_endpoint.provisioning_state in [\"Failed\", \"Canceled\"]:\n",
        "        print(f\"Endpoint {ENDPOINT_NAME} is in {existing_endpoint.provisioning_state} state. Deleting...\")\n",
        "        ml_client.online_endpoints.begin_delete(ENDPOINT_NAME).result()\n",
        "        print(f\"Deleted failed endpoint {ENDPOINT_NAME}\")\n",
        "        time.sleep(5)  # Wait for deletion to propagate\n",
        "except Exception:\n",
        "    # Endpoint doesn't exist or other error - proceed with creation\n",
        "    pass\n",
        "\n",
        "endpoint = ManagedOnlineEndpoint(\n",
        "    name=ENDPOINT_NAME,\n",
        "    auth_mode=\"key\",\n",
        "    description=\"Online endpoint serving the churn model\",\n",
        ")\n",
        "\n",
        "endpoint = ml_client.begin_create_or_update(endpoint).result()\n",
        "print(f\"Endpoint ready: {endpoint.name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Deploy the Model\n",
        "\n",
        "Create an online deployment referencing the registered model and preferred compute size.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Check: endpoint churn-endpoint-1763549164 exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "......................................................................................Deployment 'blue' is live\n"
          ]
        }
      ],
      "source": [
        "# Deploy the model\n",
        "deployment = ManagedOnlineDeployment(\n",
        "    name=DEPLOYMENT_NAME,\n",
        "    endpoint_name=ENDPOINT_NAME,\n",
        "    model=registered_model,\n",
        "    instance_type=os.getenv(\"AML_ONLINE_INSTANCE_TYPE\", \"Standard_D2as_v4\"),\n",
        "    instance_count=int(os.getenv(\"AML_ONLINE_INSTANCE_COUNT\", \"1\")),\n",
        ")\n",
        "\n",
        "ml_client.online_deployments.begin_create_or_update(deployment).result()\n",
        "print(f\"Deployment '{DEPLOYMENT_NAME}' is live\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Route Traffic\n",
        "\n",
        "Send 100% of endpoint traffic to the new deployment once provisioning succeeds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Readonly attribute principal_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n",
            "Readonly attribute tenant_id will be ignored in class <class 'azure.ai.ml._restclient.v2022_05_01.models._models_py3.ManagedServiceIdentity'>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Endpoint traffic updated: {'blue': 100}\n"
          ]
        }
      ],
      "source": [
        "# Route traffic to the deployment\n",
        "endpoint.traffic = {DEPLOYMENT_NAME: 100}\n",
        "ml_client.begin_create_or_update(endpoint).result()\n",
        "print(f\"Endpoint traffic updated: {endpoint.traffic}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Invoke the Endpoint\n",
        "\n",
        "Create a JSON file (e.g., sample-data.json) that matches the model schema, then call the managed endpoint to verify predictions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Invocation checklist**\n",
        "\n",
        "1. Encode categorical fields exactly as the training pipeline expects (see `sample-data.json`).\n",
        "2. Request payload must follow the MLflow pandas structure: `{\"input_data\": {\"columns\": [...], \"data\": [[...]]}}`.\n",
        "3. For quick manual tests, update the JSON file and re-run this cell; for automated smoke tests, use `az ml online-endpoint invoke` with the same payload."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Raw response: [0, 0, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "REQUEST_FILE = PROJECT_ROOT / \"sample-data.json\"\n",
        "\n",
        "if not REQUEST_FILE.exists():\n",
        "    raise FileNotFoundError(f\"{REQUEST_FILE} not found.\")\n",
        "\n",
        "response = ml_client.online_endpoints.invoke(\n",
        "    endpoint_name=ENDPOINT_NAME,\n",
        "    deployment_name=DEPLOYMENT_NAME,\n",
        "    request_file=str(REQUEST_FILE),\n",
        ")\n",
        "print(\"Raw response:\", response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Clean Up the Endpoint\n",
        "\n",
        "Delete the managed online endpoint when you are done testing to avoid ongoing compute charges.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to delete the managed endpoint when no longer needed\n",
        "# ml_client.online_endpoints.begin_delete(name=ENDPOINT_NAME)\n",
        "# print(f\"Deleted endpoint {ENDPOINT_NAME}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
