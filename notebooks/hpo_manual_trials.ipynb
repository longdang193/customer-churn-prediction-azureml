{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline Runner\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed working directory to: /workspaces/customer-churn-prediction-azureml\n"
     ]
    }
   ],
   "source": [
    "# Ensure we run from the project root so component paths resolve correctly\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _find_project_root(start_dir: Path) -> Path:\n",
    "    any_markers = {\".git\", \"pyproject.toml\", \"setup.cfg\"}\n",
    "    required_entries = {\"configs\", \"src\", \"notebooks\"}\n",
    "\n",
    "    def _looks_like_root(path: Path) -> bool:\n",
    "        return any((path / marker).exists() for marker in any_markers) and all(\n",
    "            (path / entry).exists() for entry in required_entries\n",
    "        )\n",
    "\n",
    "    for candidate in [start_dir, *start_dir.parents]:\n",
    "        if _looks_like_root(candidate):\n",
    "            return candidate\n",
    "\n",
    "    try:\n",
    "        for child in start_dir.iterdir():\n",
    "            if child.is_dir() and _looks_like_root(child):\n",
    "                return child\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "    env_override = os.getenv(\"AML_PROJECT_ROOT\")\n",
    "    if env_override:\n",
    "        return Path(env_override).resolve()\n",
    "\n",
    "    raise RuntimeError(\n",
    "        \"Unable to determine project root. Set AML_PROJECT_ROOT or start inside the repo.\"\n",
    "    )\n",
    "\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd().resolve()\n",
    "PROJECT_ROOT = _find_project_root(NOTEBOOK_DIR)\n",
    "if Path.cwd() != PROJECT_ROOT:\n",
    "    os.chdir(PROJECT_ROOT)\n",
    "print(f\"Changed working directory to: {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional\n",
    "\n",
    "import yaml\n",
    "from dotenv import load_dotenv\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import Input, MLClient, load_component\n",
    "\n",
    "# Allow importing project utilities\n",
    "import sys\n",
    "if str(PROJECT_ROOT.resolve()) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT.resolve()))\n",
    "\n",
    "import importlib\n",
    "import hpo_utils  # noqa: E402\n",
    "hpo_utils = importlib.reload(hpo_utils)\n",
    "from azure.ai.ml.sweep import Choice\n",
    "\n",
    "from src.utils import get_data_asset_config, load_azure_config  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to workspace 'churn-ml-workspace'.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(PROJECT_ROOT / \"config.env\")\n",
    "\n",
    "azure_cfg = load_azure_config()\n",
    "data_asset_cfg = get_data_asset_config()\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "ml_client = MLClient(\n",
    "    credential,\n",
    "    subscription_id=azure_cfg[\"subscription_id\"],\n",
    "    resource_group_name=azure_cfg[\"resource_group\"],\n",
    "    workspace_name=azure_cfg[\"workspace_name\"],\n",
    ")\n",
    "\n",
    "workspace_url = f\"https://ml.azure.com/?wsid=/subscriptions/{azure_cfg['subscription_id']}/resourcegroups/{azure_cfg['resource_group']}/workspaces/{azure_cfg['workspace_name']}\"\n",
    "print(f\"Connected to workspace '{azure_cfg['workspace_name']}'.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_DIR = str((PROJECT_ROOT / \"src\").resolve())\n",
    "DEFAULT_ENV = os.getenv(\"AML_DEFAULT_ENV\", \"azureml:bank-churn-env:1\")\n",
    "DEFAULT_COMPUTE = os.getenv(\"AML_COMPUTE_CLUSTER\", \"cpu-cluster\")\n",
    "PROCESSED_DATA_DATASTORE = os.getenv(\"AML_PROCESSED_DATA_DATASTORE\", \"workspaceblobstore\")\n",
    "PROCESSED_DATA_PREFIX = os.getenv(\"AML_PROCESSED_DATA_PREFIX\", \"manual-hpo-data\")\n",
    "\n",
    "hpo_cfg = hpo_utils.load_hpo_config()\n",
    "search_space_cfg = hpo_utils.build_parameter_space(hpo_cfg.get(\"search_space\", {}))\n",
    "\n",
    "train_config_path = PROJECT_ROOT / \"configs\" / \"train.yaml\"\n",
    "if not train_config_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected training config at {train_config_path}. Ensure you're running inside the repo.\"\n",
    "    )\n",
    "with train_config_path.open() as f:\n",
    "    train_cfg = yaml.safe_load(f) or {}\n",
    "\n",
    "raw_input = Input(\n",
    "    type=\"uri_folder\",\n",
    "    path=f\"azureml:{data_asset_cfg['data_asset_name']}:{data_asset_cfg['data_asset_version']}\",\n",
    "    mode=\"mount\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Output\n",
    "from azure.ai.ml.sweep import BanditPolicy\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "_URI_KEYS = (\n",
    "    \"uri\",\n",
    "    \"path\",\n",
    "    \"value\",\n",
    "    \"uri_folder\",\n",
    "    \"uri_file\",\n",
    "    \"asset_uri\",\n",
    "    \"assetUri\",\n",
    "    \"location\",\n",
    ")\n",
    "\n",
    "\n",
    "def _extract_asset_reference(container: Dict[str, Any]) -> Optional[str]:\n",
    "    asset_name = container.get(\"asset_name\") or container.get(\"assetName\")\n",
    "    asset_version = container.get(\"asset_version\") or container.get(\"assetVersion\")\n",
    "    if asset_name and asset_version:\n",
    "        return f\"azureml:{asset_name}:{asset_version}\"\n",
    "    asset_id = container.get(\"asset_id\") or container.get(\"assetId\")\n",
    "    if asset_id:\n",
    "        return asset_id\n",
    "    return None\n",
    "\n",
    "\n",
    "def _extract_uri_from_mapping(data: Optional[Dict[str, Any]]) -> Optional[str]:\n",
    "    if not data:\n",
    "        return None\n",
    "    if isinstance(data, str):\n",
    "        return data\n",
    "    containers = [data, data.get(\"metadata\") or {}]\n",
    "    for container in containers:\n",
    "        for key in _URI_KEYS:\n",
    "            value = container.get(key)\n",
    "            if value:\n",
    "                return value\n",
    "        asset_ref = _extract_asset_reference(container)\n",
    "        if asset_ref:\n",
    "            return asset_ref\n",
    "    return None\n",
    "\n",
    "\n",
    "def stream_job(job_name: str) -> None:\n",
    "    \"\"\"Stream logs for an Azure ML job.\"\"\"\n",
    "    print(f\"Streaming logs for job: {job_name}\")\n",
    "    ml_client.jobs.stream(job_name)\n",
    "\n",
    "\n",
    "def _resolve_output_uri(job_output) -> str:\n",
    "    \"\"\"Best-effort extraction of the backing URI from a job output.\"\"\"\n",
    "    if isinstance(job_output, str):\n",
    "        return job_output\n",
    "    for attr in _URI_KEYS:\n",
    "        value = getattr(job_output, attr, None)\n",
    "        if value:\n",
    "            return value\n",
    "    attr_dict = getattr(job_output, \"__dict__\", {}) or {}\n",
    "    asset_ref = _extract_asset_reference(attr_dict)\n",
    "    if asset_ref:\n",
    "        return asset_ref\n",
    "    if hasattr(job_output, \"as_dict\"):\n",
    "        data = job_output.as_dict() or {}\n",
    "        extracted = _extract_uri_from_mapping(data)\n",
    "        if extracted:\n",
    "            return extracted\n",
    "    if hasattr(job_output, \"_to_dict\"):\n",
    "        data = job_output._to_dict() or {}\n",
    "        extracted = _extract_uri_from_mapping(data)\n",
    "        if extracted:\n",
    "            return extracted\n",
    "    if isinstance(job_output, dict):\n",
    "        extracted = _extract_uri_from_mapping(job_output)\n",
    "        if extracted:\n",
    "            return extracted\n",
    "    raise AttributeError(\"Unable to resolve output URI from job output metadata.\")\n",
    "\n",
    "\n",
    "def _get_output_uri(job, output_name: str) -> str:\n",
    "    outputs = getattr(job, \"outputs\", None) or {}\n",
    "    if output_name not in outputs:\n",
    "        raise KeyError(f\"Job {job.name} has no output named '{output_name}'.\")\n",
    "    output = outputs[output_name]\n",
    "    job_dict = job._to_dict() if hasattr(job, \"_to_dict\") else {}\n",
    "    try:\n",
    "        return _resolve_output_uri(output)\n",
    "    except AttributeError:\n",
    "        fallback = _extract_uri_from_mapping((job_dict.get(\"outputs\") or {}).get(output_name) or {})\n",
    "        if fallback:\n",
    "            return fallback\n",
    "        fallback = _extract_uri_from_mapping(\n",
    "            (job_dict.get(\"job_outputs\") or {}).get(output_name) or {}\n",
    "        )\n",
    "        if fallback:\n",
    "            return fallback\n",
    "        artifact_store = os.getenv(\"AML_ARTIFACT_DATASTORE\", \"workspaceartifactstore\")\n",
    "        run_output_path = (\n",
    "            f\"azureml://datastores/{artifact_store}/paths/ExperimentRun/dcid.{job.name}/\"\n",
    "            f\"outputs/{output_name}/\"\n",
    "        )\n",
    "        print(\n",
    "            f\"Unable to locate explicit URI for {job.name}:{output_name}; \"\n",
    "            f\"falling back to {run_output_path}. Consider registering the output as a data asset.\"\n",
    "        )\n",
    "        return run_output_path\n",
    "\n",
    "\n",
    "def _wait_for_job_completion(job_name: str, poll_interval: int = 15):\n",
    "    \"\"\"Poll a job until it finishes and return the refreshed job.\"\"\"\n",
    "    while True:\n",
    "        fresh_job = ml_client.jobs.get(job_name)\n",
    "        status = getattr(fresh_job, \"status\", None)\n",
    "        if status in {\"Completed\", \"Finished\"}:\n",
    "            return fresh_job\n",
    "        if status in {\"Failed\", \"Canceled\"}:\n",
    "            raise RuntimeError(f\"Job {job_name} finished with status {status}\")\n",
    "        time.sleep(poll_interval)\n",
    "\n",
    "\n",
    "def run_data_prep_job(\n",
    "    *, wait_for_completion: bool = True, stream_logs: bool = True, poll_interval: int = 15\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Submit data prep job and return metadata (always job name, plus URI when ready).\"\"\"\n",
    "    output_subdir = f\"{PROCESSED_DATA_PREFIX}/{int(time.time())}\"\n",
    "    output_uri = f\"azureml://datastores/{PROCESSED_DATA_DATASTORE}/paths/{output_subdir}\"\n",
    "    prep_command = command(\n",
    "        code=SRC_DIR,\n",
    "        command=\"python data_prep.py --input ${{inputs.raw_data}} --output ${{outputs.processed_data}}\",\n",
    "        inputs={\"raw_data\": raw_input},\n",
    "        outputs={\"processed_data\": Output(type=\"uri_folder\", path=output_uri)},\n",
    "        environment=DEFAULT_ENV,\n",
    "        compute=DEFAULT_COMPUTE,\n",
    "        experiment_name=\"manual-hpo-data-prep\",\n",
    "        display_name=\"manual-hpo-data-prep\",\n",
    "    )\n",
    "    returned_job = ml_client.jobs.create_or_update(prep_command)\n",
    "    result = {\"job_name\": returned_job.name, \"studio_url\": returned_job.studio_url}\n",
    "    print(f\"Data prep job submitted: {returned_job.name} | Studio: {returned_job.studio_url}\")\n",
    "    if not wait_for_completion:\n",
    "        print(\n",
    "            \"Data prep job is running asynchronously; record the job name above and call \"\n",
    "            \"`fetch_processed_data_uri(job_name)` once it finishes to get the output URI.\"\n",
    "        )\n",
    "        return result\n",
    "    if stream_logs:\n",
    "        stream_job(returned_job.name)\n",
    "        completed_job = ml_client.jobs.get(returned_job.name)\n",
    "    else:\n",
    "        completed_job = _wait_for_job_completion(returned_job.name, poll_interval=poll_interval)\n",
    "    processed_uri = _get_output_uri(completed_job, \"processed_data\")\n",
    "    print(f\"Processed data available at: {processed_uri}\")\n",
    "    result[\"processed_data_uri\"] = processed_uri\n",
    "    return result\n",
    "\n",
    "\n",
    "def fetch_processed_data_uri(\n",
    "    job_name: str, output_name: str = \"processed_data\", poll_interval: int = 15\n",
    ") -> str:\n",
    "    \"\"\"Wait for an existing job to finish and return the processed data URI.\"\"\"\n",
    "    completed_job = _wait_for_job_completion(job_name, poll_interval=poll_interval)\n",
    "    processed_uri = _get_output_uri(completed_job, output_name)\n",
    "    print(f\"Processed data for {job_name} available at: {processed_uri}\")\n",
    "    return processed_uri\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional manual override of the previous data prep job name (leave blank to rely on env var).\n",
    "DATA_PREP_JOB = \"quirky_giraffe_bh47lt2h0r\"\n",
    "\n",
    "previous_data_prep_job_name = (\n",
    "    DATA_PREP_JOB.strip()\n",
    "    or os.getenv(\"AML_PREVIOUS_DATA_PREP_JOB\", \"\").strip()\n",
    ")\n",
    "if not previous_data_prep_job_name:\n",
    "    print(\"No previous data prep job specified; set DATA_PREP_JOB or AML_PREVIOUS_DATA_PREP_JOB.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data for quirky_giraffe_bh47lt2h0r available at: azureml://datastores/workspaceblobstore/paths/manual-hpo-data/1763391399\n",
      "Processed data URI for quirky_giraffe_bh47lt2h0r: azureml://datastores/workspaceblobstore/paths/manual-hpo-data/1763391399\n"
     ]
    }
   ],
   "source": [
    "# Fetch processed data URI for a previously completed data prep job.\n",
    "# Set AML_PREVIOUS_DATA_PREP_JOB (or edit the cell) to the job name you want to inspect.\n",
    "if previous_data_prep_job_name:\n",
    "    previous_processed_data_uri = fetch_processed_data_uri(previous_data_prep_job_name)\n",
    "    print(\n",
    "        f\"Processed data URI for {previous_data_prep_job_name}: {previous_processed_data_uri}\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"Set the DATA_PREP_JOB env var (or edit the cell) with the job \"\n",
    "        \"name to retrieve its processed data URI.\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prep job submitted: quirky_giraffe_bh47lt2h0r | Studio: https://ml.azure.com/runs/quirky_giraffe_bh47lt2h0r?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/rg-churn-ml-project-2025-11-15/workspaces/churn-ml-workspace&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "Streaming logs for job: quirky_giraffe_bh47lt2h0r\n",
      "RunId: quirky_giraffe_bh47lt2h0r\n",
      "Web View: https://ml.azure.com/runs/quirky_giraffe_bh47lt2h0r?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/rg-churn-ml-project-2025-11-15/workspaces/churn-ml-workspace\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: quirky_giraffe_bh47lt2h0r\n",
      "Web View: https://ml.azure.com/runs/quirky_giraffe_bh47lt2h0r?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/rg-churn-ml-project-2025-11-15/workspaces/churn-ml-workspace\n",
      "\n",
      "Processed data available at: azureml://datastores/workspaceblobstore/paths/manual-hpo-data/1763391399\n",
      "Processed data URI: azureml://datastores/workspaceblobstore/paths/manual-hpo-data/1763391399\n"
     ]
    }
   ],
   "source": [
    "DATA_PREP_ASYNC = os.getenv(\"AML_DATA_PREP_ASYNC\", \"false\").lower() in {\"true\", \"1\", \"yes\"}\n",
    "\n",
    "data_prep_result = run_data_prep_job(\n",
    "    wait_for_completion=not DATA_PREP_ASYNC,\n",
    "    stream_logs=not DATA_PREP_ASYNC,\n",
    ")\n",
    "\n",
    "data_prep_job_name = data_prep_result[\"job_name\"]\n",
    "processed_data_uri = data_prep_result.get(\"processed_data_uri\")\n",
    "if not processed_data_uri:\n",
    "    print(f\"Waiting for processed data from job {data_prep_job_name}...\")\n",
    "    processed_data_uri = fetch_processed_data_uri(data_prep_job_name)\n",
    "\n",
    "print(f\"Processed data URI: {processed_data_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training jobs will consume processed data from: azureml://datastores/workspaceblobstore/paths/manual-hpo-data/1763391399\n"
     ]
    }
   ],
   "source": [
    "# Determine which processed data URI to feed into training.\n",
    "try:\n",
    "    _latest_processed_data_uri = processed_data_uri  # from synchronous prep run\n",
    "except NameError:\n",
    "    _latest_processed_data_uri = None\n",
    "\n",
    "training_data_uri = _latest_processed_data_uri or locals().get(\"previous_processed_data_uri\")\n",
    "if not training_data_uri:\n",
    "    raise RuntimeError(\n",
    "        \"No processed data URI available. Run the data prep job above or set DATA_PREP_JOB/AML_PREVIOUS_DATA_PREP_JOB.\"\n",
    "    )\n",
    "\n",
    "print(f\"Training jobs will consume processed data from: {training_data_uri}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured sweep for rf:\n",
      "  metric: f1 (Maximize)\n",
      "  sampling: random\n",
      "  limits: max_total_trials=2 | max_concurrent=2\n",
      "  timeouts: total=180 min | trial=45 min\n",
      "  hyperparameters: rf_n_estimators, rf_max_depth, rf_min_samples_split, rf_min_samples_leaf\n",
      "-\n",
      "Configured sweep for xgboost:\n",
      "  metric: f1 (Maximize)\n",
      "  sampling: random\n",
      "  limits: max_total_trials=2 | max_concurrent=2\n",
      "  timeouts: total=180 min | trial=45 min\n",
      "  hyperparameters: xgboost_n_estimators, xgboost_max_depth, xgboost_learning_rate, xgboost_subsample, xgboost_colsample_bytree\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "# Configure sweep jobs per model (no cross-model mixing).\n",
    "budget_cfg = hpo_cfg.get(\"budget\", {})\n",
    "timeouts_cfg = hpo_cfg.get(\"timeouts\", {})\n",
    "early_cfg = hpo_cfg.get(\"early_stopping\", {})\n",
    "\n",
    "sweep_jobs = {}\n",
    "for model_name in search_space_cfg.get(\"model_types\", []):\n",
    "    model_space = search_space_cfg.get(model_name)\n",
    "    if not model_space:\n",
    "        print(f\"Skipping sweep for {model_name}: no hyperparameters defined in configs/hpo.yaml.\")\n",
    "        continue\n",
    "\n",
    "    command_segments = [\n",
    "        \"python run_sweep_trial.py\",\n",
    "        \"--data ${{inputs.processed_data}}\",\n",
    "        f\"--model-type {model_name}\",\n",
    "        \"--model-artifact-dir ${{outputs.model_output}}\",\n",
    "    ]\n",
    "\n",
    "    base_command_inputs = {\n",
    "        \"processed_data\": Input(type=\"uri_folder\", path=training_data_uri),\n",
    "    }\n",
    "\n",
    "    from azure.ai.ml.sweep import Choice\n",
    "\n",
    "    def _infer_literal_type(value):\n",
    "        if isinstance(value, bool):\n",
    "            return \"boolean\"\n",
    "        if isinstance(value, int):\n",
    "            return \"integer\"\n",
    "        if isinstance(value, float):\n",
    "            return \"number\"\n",
    "        return \"string\"\n",
    "\n",
    "    sweep_search_space = {}\n",
    "    hyperparam_names = []\n",
    "    for hp_name, hp_values in model_space.items():\n",
    "        prefixed_name = f\"{model_name}_{hp_name}\"\n",
    "        hyperparam_names.append(prefixed_name)\n",
    "        command_segments.append(f\"--{prefixed_name} ${{{{search_space.{prefixed_name}}}}}\")\n",
    "        sweep_search_space[prefixed_name] = Choice(values=hp_values)\n",
    "\n",
    "    sweep_command = \" \".join(command_segments)\n",
    "\n",
    "    base_training_command = command(\n",
    "        code=SRC_DIR,\n",
    "        command=sweep_command,\n",
    "        inputs=base_command_inputs,\n",
    "        outputs={\"model_output\": Output(type=\"uri_folder\")},\n",
    "        environment=DEFAULT_ENV,\n",
    "        compute=DEFAULT_COMPUTE,\n",
    "        display_name=f\"manual-hpo-sweep-trial-{model_name}\",\n",
    "        experiment_name=hpo_cfg.get(\"experiment_name\", \"manual-hpo-sweep\"),\n",
    "    )\n",
    "\n",
    "    early_policy = None\n",
    "    if early_cfg.get(\"enabled\"):\n",
    "        policy_name = (early_cfg.get(\"policy\", \"bandit\") or \"bandit\").lower()\n",
    "        if policy_name != \"bandit\":\n",
    "            raise ValueError(f\"Unsupported early stopping policy: {policy_name}\")\n",
    "        eval_interval = max(1, int(early_cfg.get(\"evaluation_interval\", 2)))\n",
    "        delay_eval = max(1, int(early_cfg.get(\"delay_evaluation\", eval_interval)))\n",
    "        slack_factor = early_cfg.get(\"slack_factor\")\n",
    "        slack_amount = early_cfg.get(\"slack_amount\")\n",
    "        early_policy = BanditPolicy(\n",
    "            evaluation_interval=eval_interval,\n",
    "            delay_evaluation=delay_eval,\n",
    "            slack_factor=slack_factor,\n",
    "            slack_amount=slack_amount,\n",
    "        )\n",
    "\n",
    "    sweep_kwargs = {\n",
    "        \"primary_metric\": hpo_cfg.get(\"metric\", \"f1\"),\n",
    "        \"goal\": \"Maximize\" if hpo_cfg.get(\"mode\", \"max\").lower() == \"max\" else \"Minimize\",\n",
    "        \"sampling_algorithm\": hpo_cfg.get(\"sampling_algorithm\", \"random\"),\n",
    "        \"search_space\": sweep_search_space,\n",
    "        \"early_termination_policy\": early_policy,\n",
    "    }\n",
    "    if budget_cfg.get(\"max_trials\"):\n",
    "        sweep_kwargs[\"max_total_trials\"] = budget_cfg[\"max_trials\"]\n",
    "    if budget_cfg.get(\"max_concurrent\"):\n",
    "        sweep_kwargs[\"max_concurrent_trials\"] = min(budget_cfg[\"max_concurrent\"], sweep_kwargs.get(\"max_total_trials\", budget_cfg.get(\"max_concurrent\")))\n",
    "    if timeouts_cfg.get(\"total_minutes\"):\n",
    "        sweep_kwargs[\"timeout\"] = int(timeouts_cfg[\"total_minutes\"]) * 60\n",
    "    if timeouts_cfg.get(\"trial_minutes\"):\n",
    "        sweep_kwargs[\"trial_timeout\"] = int(timeouts_cfg[\"trial_minutes\"]) * 60\n",
    "\n",
    "    sweep_job = base_training_command.sweep(**sweep_kwargs)\n",
    "    sweep_job.display_name = f\"{hpo_cfg.get('sweep_display_name', 'manual-hpo-sweep')}-{model_name}\"\n",
    "    sweep_job.experiment_name = hpo_cfg.get(\"experiment_name\", \"manual-hpo-sweep\")\n",
    "    sweep_jobs[model_name] = sweep_job\n",
    "\n",
    "    print(f\"Configured sweep for {model_name}:\")\n",
    "    print(f\"  metric: {sweep_kwargs['primary_metric']} ({sweep_kwargs['goal']})\")\n",
    "    print(f\"  sampling: {sweep_kwargs['sampling_algorithm']}\")\n",
    "    print(\n",
    "        f\"  limits: max_total_trials={sweep_kwargs.get('max_total_trials', 'auto')} | \"\n",
    "        f\"max_concurrent={sweep_kwargs.get('max_concurrent_trials', 'auto')}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"  timeouts: total={timeouts_cfg.get('total_minutes', 'inf')} min | \"\n",
    "        f\"trial={timeouts_cfg.get('trial_minutes', 'inf')} min\"\n",
    "    )\n",
    "    print(f\"  hyperparameters: {', '.join(hyperparam_names)}\")\n",
    "    print(\"-\")\n",
    "\n",
    "if not sweep_jobs:\n",
    "    raise RuntimeError(\"No sweep jobs were created. Check configs/hpo.yaml::search_space.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading src (0.24 MBs): 100%|██████████| 242621/242621 [00:03<00:00, 62082.26it/s] \n",
      "\u001b[39m\n",
      "\n",
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep job submitted for rf!\n",
      "  Name      : shy_lock_qdvrzwnvr2\n",
      "  Status    : Running\n",
      "  Studio URL: https://ml.azure.com/runs/shy_lock_qdvrzwnvr2?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/rg-churn-ml-project-2025-11-15/workspaces/churn-ml-workspace&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pathOnCompute is not a known attribute of class <class 'azure.ai.ml._restclient.v2023_04_01_preview.models._models_py3.UriFolderJobOutput'> and will be ignored\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep job submitted for xgboost!\n",
      "  Name      : gentle_ear_wx2w5x8k5t\n",
      "  Status    : Running\n",
      "  Studio URL: https://ml.azure.com/runs/gentle_ear_wx2w5x8k5t?wsid=/subscriptions/a23fa87c-802c-4fdf-9e59-e3d7969bcf31/resourcegroups/rg-churn-ml-project-2025-11-15/workspaces/churn-ml-workspace&tid=e7572e92-7aee-4713-a3c4-ba64888ad45f\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "sweep_submissions = {}\n",
    "for model_name, sweep_job in sweep_jobs.items():\n",
    "    submission = ml_client.jobs.create_or_update(sweep_job)\n",
    "    sweep_submissions[model_name] = submission\n",
    "    print(f\"Sweep job submitted for {model_name}!\")\n",
    "    print(f\"  Name      : {submission.name}\")\n",
    "    print(f\"  Status    : {submission.status}\")\n",
    "    print(f\"  Studio URL: {submission.studio_url}\")\n",
    "    print(\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- For each entry in `sweep_submissions`, use `ml_client.jobs.stream(<job.name>)` (or the Studio link) to monitor progress.\n",
    "- After completion, inspect each sweep job in Azure ML Studio to compare child trials and metrics per model.\n",
    "- Run `extract_best_params.py --parent-run-id <sweep_job_name>` for whichever sweep produced the best metrics.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
